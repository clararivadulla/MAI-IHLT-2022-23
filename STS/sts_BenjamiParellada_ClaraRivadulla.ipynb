{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWuWfLra_YOC"
   },
   "source": [
    "Lexical features, semantic features and combination. Use all \n",
    "new components: such as ML, or other options from the table\n",
    "\n",
    "\n",
    "Rubric:\n",
    "\t- Bad approach: Not using feature selection -> is penalizable using hand crafted approaches\n",
    "\t\t  - ((Using test set for anything, especially for selecting the model))\n",
    "\t- Explain why we use a subset of the features\n",
    "\t- Lexical features, semantic features and combination. Show results at least in feature selection.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldADwroS_fds",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from code_.data_reader import data_reader\n",
    "from code_.feature_extractor import Features\n",
    "from code_.model import Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoRr0_LGrEv9"
   },
   "source": [
    "# Final Project: Semantic Textual Similarity\n",
    "\n",
    "For the final project of the subject, :\n",
    "\n",
    "1. Use data set and description of task Semantic Textual Similarity in SemEval 2012.\n",
    "2. Implement some approaches to detect paraphrase using sentence similarity metrics.\n",
    "*   Explore some lexical dimensions.\n",
    "*   Explore the syntactic dimension alone.\n",
    "*   Explore the combination of both previous.\n",
    "3. Add new components at your choice (optional).\n",
    "4. Already generated word or sentence embeddings models are not allowed, such as BERT.\n",
    "5. Compare and comment the results achieved by these approaches among them and among the official results."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Structure of the project\n",
    "The whole project is contained in a general folder, `STS`, which contains the following directories with their respective files:\n",
    "- `code_`: where the `.py` files used for reading the data (`data_reader.py`), pre-processing it, extracting the desired features (`feature_extractor.py`) and defining the models (`model.py`) to be trained are.\n",
    "- `test-gold` and `train`: where test and training data is (`'SMTeuroparl'` `.txt` files).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature extraction\n",
    "Before training the model and after seeing which features give us the best possible results, we've tried with many different features. Here's a little explanation of each and every one:\n",
    "\n",
    "- **Jaccard Similarity** between **Tokens**: This is one of the simplest features, which computes the *Jaccard Similarity* between the *tokens* of every pair of sentences. We've tried this both considering and ignoring stopwords.\n",
    "- **Jaccard Similarity** between **Lemmas**: This is almost the same as the previous one, but using *lemmas* instead of tokens. We've also computed the similarity with and without stopwords.\n",
    "- **Jaccard Similarity** between **(1, 2 and 3) grams**: We've computed *unigrams*, *bigrams* and *trigrams* (with `nltk`'s `ngrams` function) for every pair of sentences and compared them with *jaccard*. Again, we've also computed them considering stopwords."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = data_reader('')\n",
    "train_features = Features(x_train).extract_all()\n",
    "test_features = Features(x_test).extract_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model: *Random Forest*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Models(train_features, test_features, y_train, y_test)\n",
    "models.RF()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}