{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3WehPiEa8M-",
    "outputId": "e2c55a9a-b518-4fea-95a7-cf3eec20d2d3"
   },
   "outputs": [],
   "source": [
    "path = 'lab8/'\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import CFG, BottomUpChartParser, BottomUpLeftCornerChartParser, LeftCornerChartParser\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display_html\n",
    "\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMuuOQ1i7qzP"
   },
   "source": [
    "# Lab 8: Parsing\n",
    "\n",
    "For the eighth practical of the subject, the goal is to try some non-probabilistic parsers, and optionally probabilistic parsers as well. The **mandatory** statement is:\n",
    "\n",
    "1. Consider the following sentence:\n",
    "`Lazy cats play with mice.`\n",
    "2. Expand the grammar of the example related to non-probabilistic chart parsers in order to subsume this new sentence.\n",
    "3. Perform the constituency parsing using a BottomUpChartParser, a BottomUpLeftCornerChartParser and a LeftCornerChartParser.\n",
    "4. For each one of them, provide the resulting tree, the number of edges and the list of explored edges.\n",
    "5. Which parser is the most efficient for parsing the sentence?\n",
    "6. Which edges are filtered out by each parser and why?\n",
    "\n",
    "The **optional** statement, which we've also accomplished, is:\n",
    "\n",
    "1. Read all pairs of sentences of the SMTeuroparl files of test set within the evaluation framework of the project.\n",
    "2. Compute the Jaccard similarity of each pair using the dependency triples from CoreNLPDependencyParser.\n",
    "3. Show the results. Do you think it could be relevant to use NEs to compute the similarity between two sentences? Justify the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQEERDONF9HP",
    "tags": []
   },
   "source": [
    "## Mandatory exercise: Non-probabilistic parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "av7OGZFMg7Fj"
   },
   "source": [
    "We add the words `\"lazy\"` (adjective, `Adj`), `\"play\"` (verb, `V`) and `\"with\"` (preposition, `PP`) in order to expand the grammar given so it satisfies the sentence `Lazy cats play with mice`. \n",
    "\n",
    "Reference: https://www.nltk.org/book/ch08.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xmpGfJcQpfdr"
   },
   "outputs": [],
   "source": [
    "grammar = CFG.fromstring('''\n",
    "  NP  -> NNS | JJ NNS | NP CC NP\n",
    "  NNS -> \"cats\" | \"dogs\" | \"mice\" | NNS CC NNS \n",
    "  JJ  -> \"big\" | \"small\"\n",
    "  CC  -> \"and\" | \"or\"\n",
    "  PP -> \"with\"\n",
    "  V -> \"play\"\n",
    "  Adj -> \"lazy\"\n",
    "  ''')\n",
    "sent = ['lazy', 'cats', 'play', 'with', 'mice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFdsYd8uA7G9"
   },
   "source": [
    "### BottomUpChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VBTDfc2iAGXm"
   },
   "outputs": [],
   "source": [
    "parser = nltk.BottomUpChartParser(grammar,trace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RYFlpm6AY-8",
    "outputId": "8126bfa4-c630-4189-ae48-769a0334b5a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|>       .       .       .       .       .| [0:0] Adj -> * 'lazy'\n",
      "|[-------]       .       .       .       .| [0:1] Adj -> 'lazy' *\n",
      "|.       >       .       .       .       .| [1:1] NNS -> * 'cats'\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       >       .       .       .       .| [1:1] NP -> * NNS\n",
      "|.       >       .       .       .       .| [1:1] NNS -> * NNS CC NNS\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|.       [------->       .       .       .| [1:2] NNS -> NNS * CC NNS\n",
      "|.       >       .       .       .       .| [1:1] NP -> * NP CC NP\n",
      "|.       [------->       .       .       .| [1:2] NP -> NP * CC NP\n",
      "|.       .       >       .       .       .| [2:2] V  -> * 'play'\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       .       >       .       .| [3:3] PP -> * 'with'\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       .       .       >       .| [4:4] NNS -> * 'mice'\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       >       .| [4:4] NP -> * NNS\n",
      "|.       .       .       .       >       .| [4:4] NNS -> * NNS CC NNS\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n",
      "|.       .       .       .       [------->| [4:5] NNS -> NNS * CC NNS\n",
      "|.       .       .       .       >       .| [4:4] NP -> * NP CC NP\n",
      "|.       .       .       .       [------->| [4:5] NP -> NP * CC NP\n"
     ]
    }
   ],
   "source": [
    "parse = parser.chart_parse(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITiU3CwVBnSU",
    "outputId": "1f4c4662-2f1f-40b6-86e1-4d07c54d60bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges:  27\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of edges:  \" + str(parse.num_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWD_zOTmDJK8",
    "outputId": "0be3f6bb-6dc2-4d3c-f781-f0501ca7c5cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Edge: [0:1] 'lazy'],\n",
       " [Edge: [1:2] 'cats'],\n",
       " [Edge: [2:3] 'play'],\n",
       " [Edge: [3:4] 'with'],\n",
       " [Edge: [4:5] 'mice'],\n",
       " [Edge: [0:0] Adj -> * 'lazy'],\n",
       " [Edge: [0:1] Adj -> 'lazy' *],\n",
       " [Edge: [1:1] NNS -> * 'cats'],\n",
       " [Edge: [1:2] NNS -> 'cats' *],\n",
       " [Edge: [1:1] NP -> * NNS],\n",
       " [Edge: [1:1] NNS -> * NNS CC NNS],\n",
       " [Edge: [1:2] NP -> NNS *],\n",
       " [Edge: [1:2] NNS -> NNS * CC NNS],\n",
       " [Edge: [1:1] NP -> * NP CC NP],\n",
       " [Edge: [1:2] NP -> NP * CC NP],\n",
       " [Edge: [2:2] V  -> * 'play'],\n",
       " [Edge: [2:3] V  -> 'play' *],\n",
       " [Edge: [3:3] PP -> * 'with'],\n",
       " [Edge: [3:4] PP -> 'with' *],\n",
       " [Edge: [4:4] NNS -> * 'mice'],\n",
       " [Edge: [4:5] NNS -> 'mice' *],\n",
       " [Edge: [4:4] NP -> * NNS],\n",
       " [Edge: [4:4] NNS -> * NNS CC NNS],\n",
       " [Edge: [4:5] NP -> NNS *],\n",
       " [Edge: [4:5] NNS -> NNS * CC NNS],\n",
       " [Edge: [4:4] NP -> * NP CC NP],\n",
       " [Edge: [4:5] NP -> NP * CC NP]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW1k-WYeDLb8"
   },
   "source": [
    "### BottomUpLeftCornerChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LaJMRlF2DPXw"
   },
   "outputs": [],
   "source": [
    "parser = nltk.BottomUpLeftCornerChartParser(grammar,trace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luDZGUK4DPXx",
    "outputId": "fb911677-ec27-4068-a908-2d61e93ccd8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|[-------]       .       .       .       .| [0:1] Adj -> 'lazy' *\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|.       [------->       .       .       .| [1:2] NNS -> NNS * CC NNS\n",
      "|.       [------->       .       .       .| [1:2] NP -> NP * CC NP\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n",
      "|.       .       .       .       [------->| [4:5] NNS -> NNS * CC NNS\n",
      "|.       .       .       .       [------->| [4:5] NP -> NP * CC NP\n"
     ]
    }
   ],
   "source": [
    "parse = parser.chart_parse(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWYsk7PkDPXx",
    "outputId": "0cfbbf97-095b-4e87-e38f-ce8b36399c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of edges:  \" + str(parse.num_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YivjlBI9DPXx",
    "outputId": "2453589f-2c01-4546-8c78-168529ddd05e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Edge: [0:1] 'lazy'],\n",
       " [Edge: [1:2] 'cats'],\n",
       " [Edge: [2:3] 'play'],\n",
       " [Edge: [3:4] 'with'],\n",
       " [Edge: [4:5] 'mice'],\n",
       " [Edge: [0:1] Adj -> 'lazy' *],\n",
       " [Edge: [1:2] NNS -> 'cats' *],\n",
       " [Edge: [1:2] NP -> NNS *],\n",
       " [Edge: [1:2] NNS -> NNS * CC NNS],\n",
       " [Edge: [1:2] NP -> NP * CC NP],\n",
       " [Edge: [2:3] V  -> 'play' *],\n",
       " [Edge: [3:4] PP -> 'with' *],\n",
       " [Edge: [4:5] NNS -> 'mice' *],\n",
       " [Edge: [4:5] NP -> NNS *],\n",
       " [Edge: [4:5] NNS -> NNS * CC NNS],\n",
       " [Edge: [4:5] NP -> NP * CC NP]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOOmX_GXDWIz"
   },
   "source": [
    "### LeftCornerChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hkSTOVfUDbJW"
   },
   "outputs": [],
   "source": [
    "parser = nltk.LeftCornerChartParser(grammar,trace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UCtF_utDbJX",
    "outputId": "b5f6937e-803b-491a-ae63-4faede12f84b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|[-------]       .       .       .       .| [0:1] Adj -> 'lazy' *\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n"
     ]
    }
   ],
   "source": [
    "parse = parser.chart_parse(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOpjkCn4DbJY",
    "outputId": "1f3f7007-53f6-4201-a2ad-c9ee56c7eac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges:  12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of edges:  \" + str(parse.num_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SS0BGvx7DbJY",
    "outputId": "9bb8d941-43cb-4611-c762-6085572ae3f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Edge: [0:1] 'lazy'],\n",
       " [Edge: [1:2] 'cats'],\n",
       " [Edge: [2:3] 'play'],\n",
       " [Edge: [3:4] 'with'],\n",
       " [Edge: [4:5] 'mice'],\n",
       " [Edge: [0:1] Adj -> 'lazy' *],\n",
       " [Edge: [1:2] NNS -> 'cats' *],\n",
       " [Edge: [1:2] NP -> NNS *],\n",
       " [Edge: [2:3] V  -> 'play' *],\n",
       " [Edge: [3:4] PP -> 'with' *],\n",
       " [Edge: [4:5] NNS -> 'mice' *],\n",
       " [Edge: [4:5] NP -> NNS *]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUJ7w1FuGNb1"
   },
   "source": [
    "### **Conclusions**\n",
    "\n",
    "**Which parser is the most efficient for parsing the sentence?**\n",
    "\n",
    "**Which edges are filtered out by each parser and why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1txa_-0hGB1h",
    "tags": []
   },
   "source": [
    "## Optional exercise: Dependency parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mJzm_UqKoar"
   },
   "source": [
    "To use, we first need to download and run the CoreNLP server on `localhost:9000` by following the next few steps:\n",
    "\n",
    "1. Download CoreNLP at https://stanfordnlp.github.io/CoreNLP/download.html\n",
    "2. Unzip the files and run the following command in the that directory to start the server: `java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "0pw1gRZaJur1",
    "outputId": "d675e2be-5ff2-48cf-d570-d2748d76dd3c"
   },
   "outputs": [],
   "source": [
    "parser = CoreNLPDependencyParser(url='http://localhost:9000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_jaccard_distance(sentence1, sentence2):\n",
    "    if len(sentence1.union(sentence2)) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 5*(1 - jaccard_distance(sentence1, sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(function_preprocess):\n",
    "    dt = pd.read_csv(path + 'STS.input.SMTeuroparl.txt', sep='\\t', header = None)\n",
    "    dt[2] = dt.apply(lambda row: function_preprocess(row[0]), axis = 1)\n",
    "    dt[3] = dt.apply(lambda row: function_preprocess(row[1]), axis = 1)\n",
    "    dt['gs'] = pd.read_csv(path + 'STS.gs.SMTeuroparl.txt', sep='\\t', header = None)\n",
    "    dt['jac'] = dt.apply(lambda row: apply_jaccard_distance(row[2], row[3]), axis = 1)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_CoreNLDPependencyParser(sentence):\n",
    "    parse, = parser.raw_parse(sentence)\n",
    "    triples = []\n",
    "    for governor, dep, dependent in parse.triples():\n",
    "        triples.append((governor, dep, dependent))\n",
    "    return set(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data_reader(apply_CoreNLDPependencyParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d24cf_\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >0</th>\n",
       "      <th class=\"col_heading level0 col1\" >1</th>\n",
       "      <th class=\"col_heading level0 col2\" >2</th>\n",
       "      <th class=\"col_heading level0 col3\" >3</th>\n",
       "      <th class=\"col_heading level0 col4\" >gs</th>\n",
       "      <th class=\"col_heading level0 col5\" >jac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d24cf_level0_row0\" class=\"row_heading level0 row0\" >373</th>\n",
       "      <td id=\"T_d24cf_row0_col0\" class=\"data row0 col0\" >Van Orden Report (A5-0241/2000)</td>\n",
       "      <td id=\"T_d24cf_row0_col1\" class=\"data row0 col1\" >Van Orden report (A5-0241 / 2000)</td>\n",
       "      <td id=\"T_d24cf_row0_col2\" class=\"data row0 col2\" >{(('Report', 'NNP'), 'dep', ('A5', 'NN')), (('Report', 'NNP'), 'punct', ('(', '-LRB-')), (('A5', 'NN'), 'nummod', ('0241/2000', 'CD')), (('Report', 'NNP'), 'compound', ('Orden', 'NNP')), (('A5', 'NN'), 'punct', ('-', 'HYPH')), (('Report', 'NNP'), 'punct', (')', '-RRB-')), (('Report', 'NNP'), 'compound', ('Van', 'NNP'))}</td>\n",
       "      <td id=\"T_d24cf_row0_col3\" class=\"data row0 col3\" >{(('A5', 'NN'), 'nmod', ('2000', 'CD')), (('report', 'NN'), 'dep', ('A5', 'NN')), (('A5', 'NN'), 'nummod', ('0241', 'CD')), (('A5', 'NN'), 'punct', ('-', 'HYPH')), (('report', 'NN'), 'punct', ('(', '-LRB-')), (('2000', 'CD'), 'dep', ('/', 'SYM')), (('Orden', 'NNP'), 'compound', ('Van', 'NNP')), (('report', 'NN'), 'compound', ('Orden', 'NNP')), (('report', 'NN'), 'punct', (')', '-RRB-'))}</td>\n",
       "      <td id=\"T_d24cf_row0_col4\" class=\"data row0 col4\" >5.000000</td>\n",
       "      <td id=\"T_d24cf_row0_col5\" class=\"data row0 col5\" >0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d24cf_level0_row1\" class=\"row_heading level0 row1\" >374</th>\n",
       "      <td id=\"T_d24cf_row1_col0\" class=\"data row1 col0\" >The European Union has got to do something and do it quickly.</td>\n",
       "      <td id=\"T_d24cf_row1_col1\" class=\"data row1 col1\" >It suits that the European Union is implied and that it makesit rapidly.</td>\n",
       "      <td id=\"T_d24cf_row1_col2\" class=\"data row1 col2\" >{(('Union', 'NNP'), 'compound', ('European', 'NNP')), (('got', 'VBN'), 'aux', ('has', 'VBZ')), (('Union', 'NNP'), 'det', ('The', 'DT')), (('do', 'VBP'), 'cc', ('and', 'CC')), (('got', 'VBN'), 'punct', ('.', '.')), (('got', 'VBN'), 'nsubj', ('Union', 'NNP')), (('do', 'VB'), 'mark', ('to', 'TO')), (('do', 'VBP'), 'obj', ('it', 'PRP')), (('do', 'VB'), 'obj', ('something', 'NN')), (('got', 'VBN'), 'xcomp', ('do', 'VB')), (('do', 'VBP'), 'advmod', ('quickly', 'RB')), (('got', 'VBN'), 'conj', ('do', 'VBP'))}</td>\n",
       "      <td id=\"T_d24cf_row1_col3\" class=\"data row1 col3\" >{(('Union', 'NNP'), 'compound', ('European', 'NNP')), (('rapidly', 'RB'), 'nsubj', ('it', 'PRP')), (('rapidly', 'RB'), 'cc', ('and', 'CC')), (('suits', 'VBZ'), 'nsubj', ('It', 'PRP')), (('implied', 'VBN'), 'aux:pass', ('is', 'VBZ')), (('implied', 'VBN'), 'nsubj:pass', ('Union', 'NNP')), (('suits', 'VBZ'), 'ccomp', ('implied', 'VBN')), (('implied', 'VBN'), 'conj', ('rapidly', 'RB')), (('Union', 'NNP'), 'det', ('the', 'DT')), (('implied', 'VBN'), 'mark', ('that', 'IN')), (('suits', 'VBZ'), 'punct', ('.', '.')), (('rapidly', 'RB'), 'dep', ('makesit', 'FW')), (('rapidly', 'RB'), 'mark', ('that', 'IN'))}</td>\n",
       "      <td id=\"T_d24cf_row1_col4\" class=\"data row1 col4\" >3.000000</td>\n",
       "      <td id=\"T_d24cf_row1_col5\" class=\"data row1 col5\" >0.208333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "styler = dt.iloc[[373, 374]].style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3194108246321566"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(dt['gs'], dt['jac'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Conclusions**\n",
    "\n",
    "**Do you think it could be relevant to use NEs to compute the similarity between two sentences?**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "36a8eceb321d9d60e8a630f551f1b4d07b5955962ef9cddc0b9d8a46c08fd6c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
