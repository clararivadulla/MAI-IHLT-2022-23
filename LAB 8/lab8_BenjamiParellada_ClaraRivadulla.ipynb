{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3WehPiEa8M-",
    "outputId": "e2c55a9a-b518-4fea-95a7-cf3eec20d2d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/beny/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'lab8/'\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import CFG, BottomUpChartParser, BottomUpLeftCornerChartParser, LeftCornerChartParser\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display_html\n",
    "import svgling\n",
    "import contextlib\n",
    "\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMuuOQ1i7qzP"
   },
   "source": [
    "# Lab 8: Parsing\n",
    "\n",
    "For the eighth practical of the subject, the goal is to try some non-probabilistic parsers, and optionally probabilistic parsers as well. The **mandatory** statement is:\n",
    "\n",
    "1. Consider the following sentence:\n",
    "`Lazy cats play with mice.`\n",
    "2. Expand the grammar of the example related to non-probabilistic chart parsers in order to subsume this new sentence.\n",
    "3. Perform the constituency parsing using a BottomUpChartParser, a BottomUpLeftCornerChartParser and a LeftCornerChartParser.\n",
    "4. For each one of them, provide the resulting tree, the number of edges and the list of explored edges.\n",
    "5. Which parser is the most efficient for parsing the sentence?\n",
    "6. Which edges are filtered out by each parser and why?\n",
    "\n",
    "The **optional** statement, which we've also accomplished, is:\n",
    "\n",
    "1. Read all pairs of sentences of the SMTeuroparl files of test set within the evaluation framework of the project.\n",
    "2. Compute the Jaccard similarity of each pair using the dependency triples from CoreNLPDependencyParser.\n",
    "3. Show the results. Do you think it could be relevant to use NEs to compute the similarity between two sentences? Justify the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQEERDONF9HP",
    "tags": []
   },
   "source": [
    "## Mandatory exercise: Non-probabilistic parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "av7OGZFMg7Fj"
   },
   "source": [
    "We add the words `\"lazy\"` (adjective, `Adj`), `\"play\"` (verb, `V`) and `\"with\"` (preposition, `PP`) in order to expand the grammar given so it satisfies the sentence `Lazy cats play with mice`. \n",
    "\n",
    "Reference: https://www.nltk.org/book/ch08.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "xmpGfJcQpfdr"
   },
   "outputs": [],
   "source": [
    "grammar = CFG.fromstring('''\n",
    "  S   -> NP VP\n",
    "  VP -> V | V PP NP\n",
    "  NP  ->  NNS | JJ NNS\n",
    "  NNS -> \"cats\" | \"mice\" \n",
    "  PP  -> \"with\"\n",
    "  V   -> \"play\"\n",
    "  JJ  -> \"Lazy\"\n",
    "  ''')\n",
    "sent = ['Lazy', 'cats', 'play', 'with', 'mice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['Parser', 'Edges', 'Trees'])\n",
    "def parsers(grammar, sent, parser_func):\n",
    "    parser = getattr(nltk, parser_func)(grammar, trace=1)\n",
    "    parse = parser.parse(sent)\n",
    "    trees = [t for t in parse]\n",
    "    with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "        parse = parser.chart_parse(sent)\n",
    "    print('-'*80)\n",
    "    print('Number of trees:', len(trees))\n",
    "    print('Number of edges:', parse.num_edges())\n",
    "    print('-'*80)\n",
    "\n",
    "    [print(edge) for edge in parse.edges()]\n",
    "    return parse.num_edges(), len(trees), trees[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFdsYd8uA7G9"
   },
   "source": [
    "### BottomUpChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  Lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'Lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|>       .       .       .       .       .| [0:0] JJ -> * 'Lazy'\n",
      "|[-------]       .       .       .       .| [0:1] JJ -> 'Lazy' *\n",
      "|>       .       .       .       .       .| [0:0] NP -> * JJ NNS\n",
      "|[------->       .       .       .       .| [0:1] NP -> JJ * NNS\n",
      "|.       >       .       .       .       .| [1:1] NNS -> * 'cats'\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       >       .       .       .       .| [1:1] NP -> * NNS\n",
      "|[---------------]       .       .       .| [0:2] NP -> JJ NNS *\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|.       >       .       .       .       .| [1:1] S  -> * NP VP\n",
      "|.       [------->       .       .       .| [1:2] S  -> NP * VP\n",
      "|>       .       .       .       .       .| [0:0] S  -> * NP VP\n",
      "|[--------------->       .       .       .| [0:2] S  -> NP * VP\n",
      "|.       .       >       .       .       .| [2:2] V  -> * 'play'\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       >       .       .       .| [2:2] VP -> * V\n",
      "|.       .       >       .       .       .| [2:2] VP -> * V PP NP\n",
      "|.       .       [-------]       .       .| [2:3] VP -> V *\n",
      "|.       .       [------->       .       .| [2:3] VP -> V * PP NP\n",
      "|.       [---------------]       .       .| [1:3] S  -> NP VP *\n",
      "|[-----------------------]       .       .| [0:3] S  -> NP VP *\n",
      "|.       .       .       >       .       .| [3:3] PP -> * 'with'\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       [--------------->       .| [2:4] VP -> V PP * NP\n",
      "|.       .       .       .       >       .| [4:4] NNS -> * 'mice'\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       >       .| [4:4] NP -> * NNS\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n",
      "|.       .       .       .       >       .| [4:4] S  -> * NP VP\n",
      "|.       .       [-----------------------]| [2:5] VP -> V PP NP *\n",
      "|.       .       .       .       [------->| [4:5] S  -> NP * VP\n",
      "|.       [-------------------------------]| [1:5] S  -> NP VP *\n",
      "|[=======================================]| [0:5] S  -> NP VP *\n",
      "--------------------------------------------------------------------------------\n",
      "Number of trees: 1\n",
      "Number of edges: 38\n",
      "--------------------------------------------------------------------------------\n",
      "[0:1] 'Lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:0] JJ -> * 'Lazy'\n",
      "[0:1] JJ -> 'Lazy' *\n",
      "[0:0] NP -> * JJ NNS\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:1] NNS -> * 'cats'\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:1] NP -> * NNS\n",
      "[0:2] NP -> JJ NNS *\n",
      "[1:2] NP -> NNS *\n",
      "[1:1] S  -> * NP VP\n",
      "[1:2] S  -> NP * VP\n",
      "[0:0] S  -> * NP VP\n",
      "[0:2] S  -> NP * VP\n",
      "[2:2] V  -> * 'play'\n",
      "[2:3] V  -> 'play' *\n",
      "[2:2] VP -> * V\n",
      "[2:2] VP -> * V PP NP\n",
      "[2:3] VP -> V *\n",
      "[2:3] VP -> V * PP NP\n",
      "[1:3] S  -> NP VP *\n",
      "[0:3] S  -> NP VP *\n",
      "[3:3] PP -> * 'with'\n",
      "[3:4] PP -> 'with' *\n",
      "[2:4] VP -> V PP * NP\n",
      "[4:4] NNS -> * 'mice'\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:4] NP -> * NNS\n",
      "[4:5] NP -> NNS *\n",
      "[4:4] S  -> * NP VP\n",
      "[2:5] VP -> V PP NP *\n",
      "[4:5] S  -> NP * VP\n",
      "[1:5] S  -> NP VP *\n",
      "[0:5] S  -> NP VP *\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,240.0,216.0\" width=\"240px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lazy</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cats</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">play</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">with</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mice</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "TreeLayout(Tree('S', [Tree('NP', [Tree('JJ', ['Lazy']), Tree('NNS', ['cats'])]), Tree('VP', [Tree('V', ['play']), Tree('PP', ['with']), Tree('NP', [Tree('NNS', ['mice'])])])]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, trees, tree = parsers(grammar, sent, 'BottomUpChartParser')\n",
    "results.loc[len(results)] = ['Bottom Up', edges, trees] \n",
    "svgling.draw_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW1k-WYeDLb8"
   },
   "source": [
    "### BottomUpLeftCornerChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  Lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'Lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|[-------]       .       .       .       .| [0:1] JJ -> 'Lazy' *\n",
      "|[------->       .       .       .       .| [0:1] NP -> JJ * NNS\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|[---------------]       .       .       .| [0:2] NP -> JJ NNS *\n",
      "|[--------------->       .       .       .| [0:2] S  -> NP * VP\n",
      "|.       [------->       .       .       .| [1:2] S  -> NP * VP\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       [-------]       .       .| [2:3] VP -> V *\n",
      "|.       .       [------->       .       .| [2:3] VP -> V * PP NP\n",
      "|[-----------------------]       .       .| [0:3] S  -> NP VP *\n",
      "|.       [---------------]       .       .| [1:3] S  -> NP VP *\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       [--------------->       .| [2:4] VP -> V PP * NP\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n",
      "|.       .       .       .       [------->| [4:5] S  -> NP * VP\n",
      "|.       .       [-----------------------]| [2:5] VP -> V PP NP *\n",
      "|[=======================================]| [0:5] S  -> NP VP *\n",
      "|.       [-------------------------------]| [1:5] S  -> NP VP *\n",
      "--------------------------------------------------------------------------------\n",
      "Number of trees: 1\n",
      "Number of edges: 25\n",
      "--------------------------------------------------------------------------------\n",
      "[0:1] 'Lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:1] JJ -> 'Lazy' *\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:2] NP -> NNS *\n",
      "[0:2] NP -> JJ NNS *\n",
      "[0:2] S  -> NP * VP\n",
      "[1:2] S  -> NP * VP\n",
      "[2:3] V  -> 'play' *\n",
      "[2:3] VP -> V *\n",
      "[2:3] VP -> V * PP NP\n",
      "[0:3] S  -> NP VP *\n",
      "[1:3] S  -> NP VP *\n",
      "[3:4] PP -> 'with' *\n",
      "[2:4] VP -> V PP * NP\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:5] NP -> NNS *\n",
      "[4:5] S  -> NP * VP\n",
      "[2:5] VP -> V PP NP *\n",
      "[0:5] S  -> NP VP *\n",
      "[1:5] S  -> NP VP *\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,240.0,216.0\" width=\"240px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lazy</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cats</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">play</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">with</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mice</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "TreeLayout(Tree('S', [Tree('NP', [Tree('JJ', ['Lazy']), Tree('NNS', ['cats'])]), Tree('VP', [Tree('V', ['play']), Tree('PP', ['with']), Tree('NP', [Tree('NNS', ['mice'])])])]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, trees, tree = parsers(grammar, sent, 'BottomUpLeftCornerChartParser')\n",
    "results.loc[len(results)] = ['Bottom Up Left Corner', edges, trees] \n",
    "svgling.draw_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOOmX_GXDWIz"
   },
   "source": [
    "### LeftCornerChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  Lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'Lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|[-------]       .       .       .       .| [0:1] JJ -> 'Lazy' *\n",
      "|[------->       .       .       .       .| [0:1] NP -> JJ * NNS\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|[---------------]       .       .       .| [0:2] NP -> JJ NNS *\n",
      "|[--------------->       .       .       .| [0:2] S  -> NP * VP\n",
      "|.       [------->       .       .       .| [1:2] S  -> NP * VP\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       [-------]       .       .| [2:3] VP -> V *\n",
      "|.       .       [------->       .       .| [2:3] VP -> V * PP NP\n",
      "|[-----------------------]       .       .| [0:3] S  -> NP VP *\n",
      "|.       [---------------]       .       .| [1:3] S  -> NP VP *\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       [--------------->       .| [2:4] VP -> V PP * NP\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n",
      "|.       .       [-----------------------]| [2:5] VP -> V PP NP *\n",
      "|[=======================================]| [0:5] S  -> NP VP *\n",
      "|.       [-------------------------------]| [1:5] S  -> NP VP *\n",
      "--------------------------------------------------------------------------------\n",
      "Number of trees: 1\n",
      "Number of edges: 24\n",
      "--------------------------------------------------------------------------------\n",
      "[0:1] 'Lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:1] JJ -> 'Lazy' *\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:2] NP -> NNS *\n",
      "[0:2] NP -> JJ NNS *\n",
      "[0:2] S  -> NP * VP\n",
      "[1:2] S  -> NP * VP\n",
      "[2:3] V  -> 'play' *\n",
      "[2:3] VP -> V *\n",
      "[2:3] VP -> V * PP NP\n",
      "[0:3] S  -> NP VP *\n",
      "[1:3] S  -> NP VP *\n",
      "[3:4] PP -> 'with' *\n",
      "[2:4] VP -> V PP * NP\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:5] NP -> NNS *\n",
      "[2:5] VP -> V PP NP *\n",
      "[0:5] S  -> NP VP *\n",
      "[1:5] S  -> NP VP *\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,240.0,216.0\" width=\"240px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lazy</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cats</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">play</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">with</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mice</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "TreeLayout(Tree('S', [Tree('NP', [Tree('JJ', ['Lazy']), Tree('NNS', ['cats'])]), Tree('VP', [Tree('V', ['play']), Tree('PP', ['with']), Tree('NP', [Tree('NNS', ['mice'])])])]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, trees, tree = parsers(grammar, sent, 'LeftCornerChartParser')\n",
    "results.loc[len(results)] = ['Left Corner', edges, trees] \n",
    "svgling.draw_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUJ7w1FuGNb1"
   },
   "source": [
    "### **Conclusions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parser</th>\n",
       "      <th>Edges</th>\n",
       "      <th>Trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bottom Up</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bottom Up Left Corner</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Left Corner</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Parser  Edges  Trees\n",
       "0              Bottom Up     38      1\n",
       "1  Bottom Up Left Corner     25      1\n",
       "2            Left Corner     24      1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which parser is the most efficient for parsing the sentence?**\n",
    "\n",
    "We have seen that all three parsers correctly parse the sentence. The main difference, in this case, is in the number of edges the parser needs to return the final tree. The number of edges basically means the efficiency of the parser in returning the tree, where less edges means more efficiency, i.e. less edges traversed to complete the parse.\n",
    "\n",
    "We see in the summary table, that the the Bottom Up parser returns the worst results with 38 edges, while the Bottom Left Corner and the Left Corner return almost identical results, with the Left Corner beating the Bottom Up Left Corner by one edge.\n",
    "\n",
    "\n",
    "**Which edges are filtered out by each parser and why?**\n",
    "\n",
    "Comparing the Bottom Up, with the Bottom Up Left Corner, we see that the Bottom up has a few more edges. For example, it always has the `*` on the left first. These have been removed on the Bottom Up Left Corner.\n",
    "\n",
    "- **Bottom-Up**: it takes the input string and tries to combine words to constituents and constituents to bigger constituents using the grammar rules from right to left. In doing so, any constituent that can be built are built; no matter whether they fit into the constituent that we are working on a the moment or not.\n",
    "\n",
    "- **Left-Corner**: alternates steps of bottom-up processing with top-down predictions. It imposes top-down constraints that what follow in what the following input string can be. It starts with top-down prediction fixing the category that is to be recognized and then takes a bottom-up step and alternates between the both until it is subsumed.\n",
    "\n",
    "For example, on the Bottom Up, the following appears:\n",
    "```\n",
    "[0:0] JJ -> * 'Lazy'\n",
    "[0:0] NP -> * JJ NNS\n",
    "[1:1] NNS -> * 'cats'\n",
    "[1:1] NP -> * NNS\n",
    "[1:1] S  -> * NP VP\n",
    "[0:0] S  -> * NP VP\n",
    "[2:2] V  -> * 'play'\n",
    "[2:2] VP -> * V\n",
    "[2:2] VP -> * V PP NP\n",
    "[4:4] NP -> * NNS\n",
    "[2:2] VP -> * V\n",
    "[3:3] PP -> * 'with'\n",
    "[4:4] NNS -> * 'mice'\n",
    "```\n",
    "\n",
    "Every edge starts with the `* constituent` and this is filtered on the Bottom Up Left Corner and Left Corner. Thanks to the left corner filtering.\n",
    "\n",
    "\n",
    "Comparing Bottom Up Left Corner with Left Corner, we can see that the Left Corner does not have the edge `[4:5] S  -> NP * VP`, which the bottom up left corner does have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1txa_-0hGB1h",
    "tags": []
   },
   "source": [
    "## Optional exercise: Dependency parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mJzm_UqKoar"
   },
   "source": [
    "To use, we first need to download and run the CoreNLP server on `localhost:9000` by following the next few steps:\n",
    "\n",
    "1. Download CoreNLP at https://stanfordnlp.github.io/CoreNLP/download.html\n",
    "2. Unzip the files and run the following command in the that directory to start the server: `java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000`\n",
    "\n",
    "`java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -preload tokenize,ssplit,pos,lemma,ner,parse,depparse -status_port 9000 -port 9000 -timeout 15000 & `\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "0pw1gRZaJur1",
    "outputId": "d675e2be-5ff2-48cf-d570-d2748d76dd3c"
   },
   "outputs": [],
   "source": [
    "parser = CoreNLPDependencyParser(url='http://localhost:9000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_jaccard_distance(sentence1, sentence2):\n",
    "    if len(sentence1.union(sentence2)) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 5*(1 - jaccard_distance(sentence1, sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(function_preprocess):\n",
    "    dt = pd.read_csv(path + 'STS.input.SMTeuroparl.txt', sep='\\t', header = None)\n",
    "    dt[2] = dt.apply(lambda row: function_preprocess(row[0]), axis = 1)\n",
    "    dt[3] = dt.apply(lambda row: function_preprocess(row[1]), axis = 1)\n",
    "    dt['gs'] = pd.read_csv(path + 'STS.gs.SMTeuroparl.txt', sep='\\t', header = None)\n",
    "    dt['jac'] = dt.apply(lambda row: apply_jaccard_distance(row[2], row[3]), axis = 1)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = set(nltk.corpus.stopwords.words('english')) # english stopwords\n",
    "\n",
    "\n",
    "def apply_CoreNLDPependencyParser(sentence):\n",
    "    parse, = parser.raw_parse(sentence)\n",
    "    triples = []\n",
    "    for governor, dep, dependent in parse.triples():\n",
    "        if dep == 'punct' or governor[0].lower() in stopw:\n",
    "            continue\n",
    "        triples.append(( (governor[0].lower(), governor[1]), dep, (dependent[0].lower(), dependent[1])))\n",
    "    return set(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data_reader(apply_CoreNLDPependencyParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_37789\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_37789_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_37789_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_37789_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_37789_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_37789_level0_col4\" class=\"col_heading level0 col4\" >gs</th>\n",
       "      <th id=\"T_37789_level0_col5\" class=\"col_heading level0 col5\" >jac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_37789_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_37789_row0_col0\" class=\"data row0 col0\" >The leaders have now been given a new chance and let us hope they seize it.</td>\n",
       "      <td id=\"T_37789_row0_col1\" class=\"data row0 col1\" >The leaders benefit aujourd' hui of a new luck and let's let them therefore seize it.</td>\n",
       "      <td id=\"T_37789_row0_col2\" class=\"data row0 col2\" >{(('seize', 'VB'), 'nsubj', ('they', 'PRP')), (('given', 'VBN'), 'aux:pass', ('been', 'VBN')), (('let', 'VB'), 'ccomp', ('hope', 'VB')), (('leaders', 'NNS'), 'det', ('the', 'DT')), (('given', 'VBN'), 'aux', ('have', 'VBP')), (('hope', 'VB'), 'nsubj', ('us', 'PRP')), (('chance', 'NN'), 'amod', ('new', 'JJ')), (('seize', 'VB'), 'obj', ('it', 'PRP')), (('given', 'VBN'), 'advmod', ('now', 'RB')), (('given', 'VBN'), 'conj', ('let', 'VB')), (('chance', 'NN'), 'det', ('a', 'DT')), (('given', 'VBN'), 'nsubj:pass', ('leaders', 'NNS')), (('given', 'VBN'), 'obj', ('chance', 'NN')), (('let', 'VB'), 'cc', ('and', 'CC')), (('hope', 'VB'), 'ccomp', ('seize', 'VB'))}</td>\n",
       "      <td id=\"T_37789_row0_col3\" class=\"data row0 col3\" >{(('luck', 'NN'), 'case', ('of', 'IN')), (('let', 'VB'), 'nsubj', (\"'s\", 'PRP')), (('seize', 'VB'), 'nsubj', ('them', 'PRP')), (('hui', 'NNP'), 'nmod', ('luck', 'NN')), (('seize', 'VB'), 'advmod', ('therefore', 'RB')), (('luck', 'NN'), 'det', ('a', 'DT')), (('leaders', 'NNS'), 'det', ('the', 'DT')), (('seize', 'VB'), 'obj', ('it', 'PRP')), (('luck', 'NN'), 'amod', ('new', 'JJ')), (('benefit', 'VBP'), 'conj', ('let', 'VB')), (('let', 'VB'), 'ccomp', ('seize', 'VB')), (('benefit', 'VBP'), 'nsubj', ('leaders', 'NNS')), (('let', 'VB'), 'cc', ('and', 'CC')), (('let', 'VB'), 'ccomp', ('let', 'VB')), (('hui', 'NNP'), 'compound', ('aujourd', 'NN')), (('benefit', 'VBP'), 'obj', ('hui', 'NNP'))}</td>\n",
       "      <td id=\"T_37789_row0_col4\" class=\"data row0 col4\" >4.500000</td>\n",
       "      <td id=\"T_37789_row0_col5\" class=\"data row0 col5\" >0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37789_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_37789_row1_col0\" class=\"data row1 col0\" >Amendment No 7 proposes certain changes in the references to paragraphs.</td>\n",
       "      <td id=\"T_37789_row1_col1\" class=\"data row1 col1\" >Amendment No 7 is proposing certain changes in the references to paragraphs.</td>\n",
       "      <td id=\"T_37789_row1_col2\" class=\"data row1 col2\" >{(('proposes', 'VBZ'), 'obj', ('changes', 'NNS')), (('changes', 'NNS'), 'amod', ('certain', 'JJ')), (('7', 'NNP'), 'compound', ('amendment', 'NNP')), (('references', 'NNS'), 'case', ('in', 'IN')), (('references', 'NNS'), 'det', ('the', 'DT')), (('7', 'NNP'), 'compound', ('no', 'NNP')), (('references', 'NNS'), 'nmod', ('paragraphs', 'NNS')), (('paragraphs', 'NNS'), 'case', ('to', 'IN')), (('proposes', 'VBZ'), 'nsubj', ('7', 'NNP')), (('changes', 'NNS'), 'nmod', ('references', 'NNS'))}</td>\n",
       "      <td id=\"T_37789_row1_col3\" class=\"data row1 col3\" >{(('proposing', 'VBG'), 'aux', ('is', 'VBZ')), (('changes', 'NNS'), 'amod', ('certain', 'JJ')), (('7', 'NNP'), 'compound', ('amendment', 'NNP')), (('references', 'NNS'), 'case', ('in', 'IN')), (('references', 'NNS'), 'det', ('the', 'DT')), (('7', 'NNP'), 'compound', ('no', 'NNP')), (('references', 'NNS'), 'nmod', ('paragraphs', 'NNS')), (('paragraphs', 'NNS'), 'case', ('to', 'IN')), (('proposing', 'VBG'), 'nsubj', ('7', 'NNP')), (('changes', 'NNS'), 'nmod', ('references', 'NNS')), (('proposing', 'VBG'), 'obj', ('changes', 'NNS'))}</td>\n",
       "      <td id=\"T_37789_row1_col4\" class=\"data row1 col4\" >5.000000</td>\n",
       "      <td id=\"T_37789_row1_col5\" class=\"data row1 col5\" >3.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37789_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_37789_row2_col0\" class=\"data row2 col0\" >Let me remind you that our allies include fervent supporters of this tax.</td>\n",
       "      <td id=\"T_37789_row2_col1\" class=\"data row2 col1\" >I would like to remind you that among our allies, there are strong of this tax.</td>\n",
       "      <td id=\"T_37789_row2_col2\" class=\"data row2 col2\" >{(('let', 'VB'), 'ccomp', ('remind', 'VB')), (('include', 'VBP'), 'obj', ('supporters', 'NNS')), (('tax', 'NN'), 'case', ('of', 'IN')), (('tax', 'NN'), 'det', ('this', 'DT')), (('include', 'VBP'), 'nsubj', ('allies', 'NNS')), (('remind', 'VB'), 'nsubj', ('me', 'PRP')), (('supporters', 'NNS'), 'nmod', ('tax', 'NN')), (('allies', 'NNS'), 'nmod:poss', ('our', 'PRP$')), (('remind', 'VB'), 'obj', ('you', 'PRP')), (('include', 'VBP'), 'mark', ('that', 'IN')), (('supporters', 'NNS'), 'amod', ('fervent', 'JJ')), (('remind', 'VB'), 'ccomp', ('include', 'VBP'))}</td>\n",
       "      <td id=\"T_37789_row2_col3\" class=\"data row2 col3\" >{(('remind', 'VB'), 'ccomp', ('are', 'VBP')), (('tax', 'NN'), 'case', ('of', 'IN')), (('like', 'VB'), 'nsubj', ('i', 'PRP')), (('tax', 'NN'), 'det', ('this', 'DT')), (('allies', 'NNS'), 'nmod:poss', ('our', 'PRP$')), (('remind', 'VB'), 'obj', ('you', 'PRP')), (('remind', 'VB'), 'mark', ('to', 'TO')), (('allies', 'NNS'), 'case', ('among', 'IN')), (('like', 'VB'), 'aux', ('would', 'MD')), (('strong', 'JJ'), 'obl', ('tax', 'NN')), (('like', 'VB'), 'xcomp', ('remind', 'VB'))}</td>\n",
       "      <td id=\"T_37789_row2_col4\" class=\"data row2 col4\" >4.250000</td>\n",
       "      <td id=\"T_37789_row2_col5\" class=\"data row2 col5\" >1.052632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "styler = dt.head(3).style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3280739664753573"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(dt['gs'], dt['jac'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is it relevant to compute the triples?**\n",
    "\n",
    "Comparing the triples like we are doing now is not relevant for the STS task. CoreNLP takes in a raw test and runs a series of steps (tokenize, split, POS, lemma, ner, deparse) to obtain a final set of annotations. Using the POS tags of these sets might be better than using the previously tested ones. However, using the entire set of triples to compare the STS results in worse results than just comparing the tokens. Hence, we might use it to extract the POS and perhaps it could improve the default NLTK results."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
