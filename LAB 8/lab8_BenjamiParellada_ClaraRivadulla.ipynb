{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3WehPiEa8M-",
    "outputId": "e2c55a9a-b518-4fea-95a7-cf3eec20d2d3"
   },
   "outputs": [],
   "source": [
    "path = 'lab8/'\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "from nltk import CFG, BottomUpChartParser, BottomUpLeftCornerChartParser, LeftCornerChartParser\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display_html\n",
    "import svgling\n",
    "import contextlib\n",
    "\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMuuOQ1i7qzP"
   },
   "source": [
    "# Lab 8: Parsing\n",
    "\n",
    "For the eighth practical of the subject, the goal is to try some non-probabilistic parsers, and optionally probabilistic parsers as well. The **mandatory** statement is:\n",
    "\n",
    "1. Consider the following sentence:\n",
    "`Lazy cats play with mice.`\n",
    "2. Expand the grammar of the example related to non-probabilistic chart parsers in order to subsume this new sentence.\n",
    "3. Perform the constituency parsing using a BottomUpChartParser, a BottomUpLeftCornerChartParser and a LeftCornerChartParser.\n",
    "4. For each one of them, provide the resulting tree, the number of edges and the list of explored edges.\n",
    "5. Which parser is the most efficient for parsing the sentence?\n",
    "6. Which edges are filtered out by each parser and why?\n",
    "\n",
    "The **optional** statement, which we've also accomplished, is:\n",
    "\n",
    "1. Read all pairs of sentences of the SMTeuroparl files of test set within the evaluation framework of the project.\n",
    "2. Compute the Jaccard similarity of each pair using the dependency triples from CoreNLPDependencyParser.\n",
    "3. Show the results. Do you think it could be relevant to use NEs to compute the similarity between two sentences? Justify the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQEERDONF9HP",
    "tags": []
   },
   "source": [
    "## Mandatory exercise: Non-probabilistic parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "av7OGZFMg7Fj"
   },
   "source": [
    "We add the words `\"Lazy\"` (adjective, `JJ`), `\"play\"` (verb, `V`) and `\"with\"` (preposition, `PP`) in order to expand the grammar given so it satisfies the sentence `Lazy cats play with mice`. Moreover, since you said to use the smallest possible grammar, we have removed some of the stuff that was previously present. We could even make it smaller by putting the exact appearance of each element to subsum, however, this causes the Bottom-Up Left-Corner and the Left-Corner parser to produce the same edges. Hence, we add a bit more \"generalization\" to see the differences between the parsers.\n",
    "\n",
    "Reference: https://www.nltk.org/book/ch08.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xmpGfJcQpfdr"
   },
   "outputs": [],
   "source": [
    "grammar = CFG.fromstring('''\n",
    "  S   -> NP VP\n",
    "  VP  -> V | V PP NP\n",
    "  NP  ->  NNS | JJ NNS\n",
    "  NNS -> \"cats\" | \"mice\" \n",
    "  PP  -> \"with\"\n",
    "  V   -> \"play\"\n",
    "  JJ  -> \"Lazy\"\n",
    "  ''')\n",
    "sent = ['Lazy', 'cats', 'play', 'with', 'mice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = ['Parser', 'Edges', 'Trees'])\n",
    "def parsers(grammar, sent, parser_func):\n",
    "    parser = getattr(nltk, parser_func)(grammar, trace=1)\n",
    "    parse = parser.parse(sent)\n",
    "    trees = [t for t in parse] # get the number of trees\n",
    "    with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f): # avoid printing to stdout, its the same tree\n",
    "        parse = parser.chart_parse(sent) # we use this to get number of edges, we could do it manually but eh\n",
    "    print('-'*80)\n",
    "    print('Number of trees:', len(trees))\n",
    "    print('Number of edges:', parse.num_edges())\n",
    "    print('-'*80)\n",
    "\n",
    "    #[print(edge) for edge in parse.edges()] # this would get a list of edges, but its the same we already see in the original trace\n",
    "    return parse.num_edges(), len(trees), trees[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFdsYd8uA7G9"
   },
   "source": [
    "### BottomUpChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  Lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'Lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|>       .       .       .       .       .| [0:0] JJ -> * 'Lazy'\n",
      "|[-------]       .       .       .       .| [0:1] JJ -> 'Lazy' *\n",
      "|>       .       .       .       .       .| [0:0] NP -> * JJ NNS\n",
      "|[------->       .       .       .       .| [0:1] NP -> JJ * NNS\n",
      "|.       >       .       .       .       .| [1:1] NNS -> * 'cats'\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       >       .       .       .       .| [1:1] NP -> * NNS\n",
      "|[---------------]       .       .       .| [0:2] NP -> JJ NNS *\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|.       >       .       .       .       .| [1:1] S  -> * NP VP\n",
      "|.       [------->       .       .       .| [1:2] S  -> NP * VP\n",
      "|>       .       .       .       .       .| [0:0] S  -> * NP VP\n",
      "|[--------------->       .       .       .| [0:2] S  -> NP * VP\n",
      "|.       .       >       .       .       .| [2:2] V  -> * 'play'\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       >       .       .       .| [2:2] VP -> * V\n",
      "|.       .       >       .       .       .| [2:2] VP -> * V PP NP\n",
      "|.       .       [-------]       .       .| [2:3] VP -> V *\n",
      "|.       .       [------->       .       .| [2:3] VP -> V * PP NP\n",
      "|.       [---------------]       .       .| [1:3] S  -> NP VP *\n",
      "|[-----------------------]       .       .| [0:3] S  -> NP VP *\n",
      "|.       .       .       >       .       .| [3:3] PP -> * 'with'\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       [--------------->       .| [2:4] VP -> V PP * NP\n",
      "|.       .       .       .       >       .| [4:4] NNS -> * 'mice'\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       >       .| [4:4] NP -> * NNS\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n",
      "|.       .       .       .       >       .| [4:4] S  -> * NP VP\n",
      "|.       .       [-----------------------]| [2:5] VP -> V PP NP *\n",
      "|.       .       .       .       [------->| [4:5] S  -> NP * VP\n",
      "|.       [-------------------------------]| [1:5] S  -> NP VP *\n",
      "|[=======================================]| [0:5] S  -> NP VP *\n",
      "--------------------------------------------------------------------------------\n",
      "Number of trees: 1\n",
      "Number of edges: 38\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,240.0,216.0\" width=\"240px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lazy</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cats</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">play</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">with</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mice</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "TreeLayout(Tree('S', [Tree('NP', [Tree('JJ', ['Lazy']), Tree('NNS', ['cats'])]), Tree('VP', [Tree('V', ['play']), Tree('PP', ['with']), Tree('NP', [Tree('NNS', ['mice'])])])]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, trees, tree = parsers(grammar, sent, 'BottomUpChartParser')\n",
    "results.loc[len(results)] = ['Bottom Up', edges, trees] \n",
    "svgling.draw_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dW1k-WYeDLb8"
   },
   "source": [
    "### BottomUpLeftCornerChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  Lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'Lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|[-------]       .       .       .       .| [0:1] JJ -> 'Lazy' *\n",
      "|[------->       .       .       .       .| [0:1] NP -> JJ * NNS\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|[---------------]       .       .       .| [0:2] NP -> JJ NNS *\n",
      "|[--------------->       .       .       .| [0:2] S  -> NP * VP\n",
      "|.       [------->       .       .       .| [1:2] S  -> NP * VP\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       [-------]       .       .| [2:3] VP -> V *\n",
      "|.       .       [------->       .       .| [2:3] VP -> V * PP NP\n",
      "|[-----------------------]       .       .| [0:3] S  -> NP VP *\n",
      "|.       [---------------]       .       .| [1:3] S  -> NP VP *\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       [--------------->       .| [2:4] VP -> V PP * NP\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n",
      "|.       .       .       .       [------->| [4:5] S  -> NP * VP\n",
      "|.       .       [-----------------------]| [2:5] VP -> V PP NP *\n",
      "|[=======================================]| [0:5] S  -> NP VP *\n",
      "|.       [-------------------------------]| [1:5] S  -> NP VP *\n",
      "--------------------------------------------------------------------------------\n",
      "Number of trees: 1\n",
      "Number of edges: 25\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,240.0,216.0\" width=\"240px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lazy</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cats</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">play</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">with</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mice</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "TreeLayout(Tree('S', [Tree('NP', [Tree('JJ', ['Lazy']), Tree('NNS', ['cats'])]), Tree('VP', [Tree('V', ['play']), Tree('PP', ['with']), Tree('NP', [Tree('NNS', ['mice'])])])]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, trees, tree = parsers(grammar, sent, 'BottomUpLeftCornerChartParser')\n",
    "results.loc[len(results)] = ['Bottom Up Left Corner', edges, trees] \n",
    "svgling.draw_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOOmX_GXDWIz"
   },
   "source": [
    "### LeftCornerChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.  Lazy .  cats .  play .  with .  mice .|\n",
      "|[-------]       .       .       .       .| [0:1] 'Lazy'\n",
      "|.       [-------]       .       .       .| [1:2] 'cats'\n",
      "|.       .       [-------]       .       .| [2:3] 'play'\n",
      "|.       .       .       [-------]       .| [3:4] 'with'\n",
      "|.       .       .       .       [-------]| [4:5] 'mice'\n",
      "|[-------]       .       .       .       .| [0:1] JJ -> 'Lazy' *\n",
      "|[------->       .       .       .       .| [0:1] NP -> JJ * NNS\n",
      "|.       [-------]       .       .       .| [1:2] NNS -> 'cats' *\n",
      "|.       [-------]       .       .       .| [1:2] NP -> NNS *\n",
      "|[---------------]       .       .       .| [0:2] NP -> JJ NNS *\n",
      "|[--------------->       .       .       .| [0:2] S  -> NP * VP\n",
      "|.       [------->       .       .       .| [1:2] S  -> NP * VP\n",
      "|.       .       [-------]       .       .| [2:3] V  -> 'play' *\n",
      "|.       .       [-------]       .       .| [2:3] VP -> V *\n",
      "|.       .       [------->       .       .| [2:3] VP -> V * PP NP\n",
      "|[-----------------------]       .       .| [0:3] S  -> NP VP *\n",
      "|.       [---------------]       .       .| [1:3] S  -> NP VP *\n",
      "|.       .       .       [-------]       .| [3:4] PP -> 'with' *\n",
      "|.       .       [--------------->       .| [2:4] VP -> V PP * NP\n",
      "|.       .       .       .       [-------]| [4:5] NNS -> 'mice' *\n",
      "|.       .       .       .       [-------]| [4:5] NP -> NNS *\n",
      "|.       .       [-----------------------]| [2:5] VP -> V PP NP *\n",
      "|[=======================================]| [0:5] S  -> NP VP *\n",
      "|.       [-------------------------------]| [1:5] S  -> NP VP *\n",
      "--------------------------------------------------------------------------------\n",
      "Number of trees: 1\n",
      "Number of edges: 24\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,240.0,216.0\" width=\"240px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lazy</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cats</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">play</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">with</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mice</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "TreeLayout(Tree('S', [Tree('NP', [Tree('JJ', ['Lazy']), Tree('NNS', ['cats'])]), Tree('VP', [Tree('V', ['play']), Tree('PP', ['with']), Tree('NP', [Tree('NNS', ['mice'])])])]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, trees, tree = parsers(grammar, sent, 'LeftCornerChartParser')\n",
    "results.loc[len(results)] = ['Left Corner', edges, trees] \n",
    "svgling.draw_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUJ7w1FuGNb1"
   },
   "source": [
    "### **Conclusions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parser</th>\n",
       "      <th>Edges</th>\n",
       "      <th>Trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bottom Up</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bottom Up Left Corner</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Left Corner</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Parser  Edges  Trees\n",
       "0              Bottom Up     38      1\n",
       "1  Bottom Up Left Corner     25      1\n",
       "2            Left Corner     24      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which parser is the most efficient for parsing the sentence?**\n",
    "\n",
    "We have seen that all three parsers correctly subsume the sentence. The main difference, in this case, is in the number of edges the parser expands before returning a valid tree. The number of edges expanded/produced basically means the efficiency of the parser in returning the tree, where fewer edges means more efficiency, i.e. fewer edges produced to complete the parse.\n",
    "\n",
    "We see in the summary table above, that the Bottom-Up parser returns the worst results with 38 edges expanded, while the Bottom-Up Left-Corner and the Left-Corner return almost identical results, with the Left-Corner (24 edges) beating the Bottom-Up Left-Corner (25 edges) by one edge.\n",
    "\n",
    "\n",
    "**Which edges are filtered out by each parser, and why?**\n",
    "\n",
    "- **Bottom-Up**: it takes the input string and tries to combine words to constituents and constituents to bigger constituents using the grammar rules from right to left. In doing so, any constituent that can be built is built; no matter whether they fit into the constituent that we are working on at the moment or not. \n",
    "\n",
    "    Comparing the Bottom-Up parser with the other two parsers, we see that the Bottom-Up expanded the most edges. These \"added\" edges that appear always have the same form, they always have the `*` on the left of a constituent. Specifically, the following 13 edges have been produced:\n",
    "    ```\n",
    "    [0:0] JJ -> * 'Lazy'\n",
    "    [0:0] NP -> * JJ NNS\n",
    "    [1:1] NNS -> * 'cats'\n",
    "    [1:1] NP -> * NNS\n",
    "    [1:1] S  -> * NP VP\n",
    "    [0:0] S  -> * NP VP\n",
    "    [2:2] V  -> * 'play'\n",
    "    [2:2] VP -> * V\n",
    "    [2:2] VP -> * V PP NP\n",
    "    [3:3] PP -> * 'with'\n",
    "    [4:4] NNS -> * 'mice'\n",
    "    [4:4] NP -> * NNS\n",
    "    [4:4] S  -> * NP VP\n",
    "    ```\n",
    "\n",
    "Every edge is of the form $A \\rightarrow {}^* B$ and these sorts of edges are filtered on the Bottom-Up Left-Corner and the Left-Corner parsers.\n",
    "\n",
    "- **Bottom-up Left-Corner**: modifies a rule of the original Bottom-Up, such to license any edge corresponding to a production whose right-hand side begins with a complete edge's left-hand side. In particular, this rule specifies that $A \\rightarrow \\alpha {}^\\ast$ licenses the edge $B \\rightarrow  A^* \\beta$ for each grammar production $B \\rightarrow A \\beta$. In other words, it filters the edges without any word subsumed. In even easier words, it only produces an edge if its left corner has already been found (the first element of the right-hand side).\n",
    "\n",
    "Comparing Bottom-Up Left-Corner with Left-Corner, we can see that the Left-Corner does not have the following edge:\n",
    "\n",
    "`[4:5] S  -> NP * VP`\n",
    "\n",
    "- **Left-Corner**: alternates steps of bottom-up processing with top-down predictions. It imposes top-down constraints in what the following input string can be. It starts with top-down prediction fixing the category that is to be recognized and then takes a bottom-up step and alternates between the both until it is subsumed. This is in theory how they work, checking the NLTK implementation seems to follow a slightly different approach, where it basically follows the same approach as the Bottom-Up Left-Corner, but filters some edges following a bottom up approach. Specifically, it filters out edges without new word subsumptions, if we have $A\\rightarrow \\alpha$ and $B \\rightarrow \\beta$ then we filter $C \\rightarrow A^* B$. Thus, in the Bottom-Up Left-Corner we had `S  -> NP * VP`, which is filtered since we have `NP -> NNS *` and `VP -> V PP * NP`. Additionally, the same 13 previous edges are also filtered from the Bottom-Up Parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1txa_-0hGB1h",
    "tags": []
   },
   "source": [
    "## Optional exercise: Dependency parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mJzm_UqKoar"
   },
   "source": [
    "To use Stanford CoreNLP, we first need to download and run the CoreNLP server on `localhost:9000` by following the next few steps:\n",
    "\n",
    "1. Download CoreNLP at https://stanfordnlp.github.io/CoreNLP/download.html\n",
    "2. Unzip the files and run the following commands in the directory to start the server: \n",
    "\n",
    "```\n",
    "cd stanford-corenlp-4.5.1/\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -preload tokenize,ssplit,pos,lemma,ner,parse,depparse -status_port 9000 -port 9000 -timeout 15000 &\n",
    "```\n",
    "\n",
    "3. Run the following commands in the notebook, it might be that the jupyter notebook and the CoreNLP server are on the same port, make sure this does not happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "0pw1gRZaJur1",
    "outputId": "d675e2be-5ff2-48cf-d570-d2748d76dd3c"
   },
   "outputs": [],
   "source": [
    "parser = CoreNLPDependencyParser(url='http://localhost:9000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_jaccard_distance(sentence1, sentence2):\n",
    "    if len(sentence1.union(sentence2)) == 0: # if the union of elements is empty, we consider the similarity to be zero\n",
    "        return 0\n",
    "    else:\n",
    "        return 5*(1 - jaccard_distance(sentence1, sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(function_preprocess):\n",
    "    dt = pd.read_csv(path + 'STS.input.SMTeuroparl.txt', sep='\\t', header = None)\n",
    "    dt[2] = dt.apply(lambda row: function_preprocess(row[0]), axis = 1)\n",
    "    dt[3] = dt.apply(lambda row: function_preprocess(row[1]), axis = 1)\n",
    "    dt['gs'] = pd.read_csv(path + 'STS.gs.SMTeuroparl.txt', sep='\\t', header = None)\n",
    "    dt['jac'] = dt.apply(lambda row: apply_jaccard_distance(row[2], row[3]), axis = 1)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = set(nltk.corpus.stopwords.words('english')) # english stopwords\n",
    "\n",
    "def apply_CoreNLDPependencyParser(sentence):\n",
    "    parse, = parser.raw_parse(sentence)\n",
    "    triples = []\n",
    "    for governor, dep, dependent in parse.triples():\n",
    "        if dep == 'punct' or governor[0].lower() in stopw:\n",
    "            continue\n",
    "        triples.append(( (governor[0].lower(), governor[1]), dep, (dependent[0].lower(), dependent[1])))\n",
    "    return set(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data_reader(apply_CoreNLDPependencyParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7daf8\" style='display:inline'>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7daf8_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_7daf8_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_7daf8_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_7daf8_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_7daf8_level0_col4\" class=\"col_heading level0 col4\" >gs</th>\n",
       "      <th id=\"T_7daf8_level0_col5\" class=\"col_heading level0 col5\" >jac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7daf8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7daf8_row0_col0\" class=\"data row0 col0\" >The leaders have now been given a new chance and let us hope they seize it.</td>\n",
       "      <td id=\"T_7daf8_row0_col1\" class=\"data row0 col1\" >The leaders benefit aujourd' hui of a new luck and let's let them therefore seize it.</td>\n",
       "      <td id=\"T_7daf8_row0_col2\" class=\"data row0 col2\" >{(('given', 'VBN'), 'aux:pass', ('been', 'VBN')), (('chance', 'NN'), 'amod', ('new', 'JJ')), (('seize', 'VB'), 'obj', ('it', 'PRP')), (('hope', 'VB'), 'ccomp', ('seize', 'VB')), (('leaders', 'NNS'), 'det', ('the', 'DT')), (('chance', 'NN'), 'det', ('a', 'DT')), (('given', 'VBN'), 'obj', ('chance', 'NN')), (('given', 'VBN'), 'nsubj:pass', ('leaders', 'NNS')), (('given', 'VBN'), 'advmod', ('now', 'RB')), (('let', 'VB'), 'cc', ('and', 'CC')), (('let', 'VB'), 'ccomp', ('hope', 'VB')), (('hope', 'VB'), 'nsubj', ('us', 'PRP')), (('given', 'VBN'), 'conj', ('let', 'VB')), (('seize', 'VB'), 'nsubj', ('they', 'PRP')), (('given', 'VBN'), 'aux', ('have', 'VBP'))}</td>\n",
       "      <td id=\"T_7daf8_row0_col3\" class=\"data row0 col3\" >{(('seize', 'VB'), 'obj', ('it', 'PRP')), (('benefit', 'VBP'), 'conj', ('let', 'VB')), (('hui', 'NNP'), 'nmod', ('luck', 'NN')), (('leaders', 'NNS'), 'det', ('the', 'DT')), (('benefit', 'VBP'), 'obj', ('hui', 'NNP')), (('let', 'VB'), 'ccomp', ('let', 'VB')), (('benefit', 'VBP'), 'nsubj', ('leaders', 'NNS')), (('let', 'VB'), 'cc', ('and', 'CC')), (('let', 'VB'), 'ccomp', ('seize', 'VB')), (('seize', 'VB'), 'nsubj', ('them', 'PRP')), (('luck', 'NN'), 'case', ('of', 'IN')), (('let', 'VB'), 'nsubj', (\"'s\", 'PRP')), (('luck', 'NN'), 'amod', ('new', 'JJ')), (('hui', 'NNP'), 'compound', ('aujourd', 'NN')), (('seize', 'VB'), 'advmod', ('therefore', 'RB')), (('luck', 'NN'), 'det', ('a', 'DT'))}</td>\n",
       "      <td id=\"T_7daf8_row0_col4\" class=\"data row0 col4\" >4.500000</td>\n",
       "      <td id=\"T_7daf8_row0_col5\" class=\"data row0 col5\" >0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7daf8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7daf8_row1_col0\" class=\"data row1 col0\" >Amendment No 7 proposes certain changes in the references to paragraphs.</td>\n",
       "      <td id=\"T_7daf8_row1_col1\" class=\"data row1 col1\" >Amendment No 7 is proposing certain changes in the references to paragraphs.</td>\n",
       "      <td id=\"T_7daf8_row1_col2\" class=\"data row1 col2\" >{(('7', 'NNP'), 'compound', ('no', 'NNP')), (('changes', 'NNS'), 'nmod', ('references', 'NNS')), (('references', 'NNS'), 'det', ('the', 'DT')), (('references', 'NNS'), 'nmod', ('paragraphs', 'NNS')), (('references', 'NNS'), 'case', ('in', 'IN')), (('proposes', 'VBZ'), 'obj', ('changes', 'NNS')), (('changes', 'NNS'), 'amod', ('certain', 'JJ')), (('paragraphs', 'NNS'), 'case', ('to', 'IN')), (('proposes', 'VBZ'), 'nsubj', ('7', 'NNP')), (('7', 'NNP'), 'compound', ('amendment', 'NNP'))}</td>\n",
       "      <td id=\"T_7daf8_row1_col3\" class=\"data row1 col3\" >{(('paragraphs', 'NNS'), 'case', ('to', 'IN')), (('7', 'NNP'), 'compound', ('no', 'NNP')), (('changes', 'NNS'), 'nmod', ('references', 'NNS')), (('references', 'NNS'), 'det', ('the', 'DT')), (('references', 'NNS'), 'nmod', ('paragraphs', 'NNS')), (('proposing', 'VBG'), 'nsubj', ('7', 'NNP')), (('references', 'NNS'), 'case', ('in', 'IN')), (('proposing', 'VBG'), 'aux', ('is', 'VBZ')), (('changes', 'NNS'), 'amod', ('certain', 'JJ')), (('proposing', 'VBG'), 'obj', ('changes', 'NNS')), (('7', 'NNP'), 'compound', ('amendment', 'NNP'))}</td>\n",
       "      <td id=\"T_7daf8_row1_col4\" class=\"data row1 col4\" >5.000000</td>\n",
       "      <td id=\"T_7daf8_row1_col5\" class=\"data row1 col5\" >3.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7daf8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7daf8_row2_col0\" class=\"data row2 col0\" >Let me remind you that our allies include fervent supporters of this tax.</td>\n",
       "      <td id=\"T_7daf8_row2_col1\" class=\"data row2 col1\" >I would like to remind you that among our allies, there are strong of this tax.</td>\n",
       "      <td id=\"T_7daf8_row2_col2\" class=\"data row2 col2\" >{(('remind', 'VB'), 'ccomp', ('include', 'VBP')), (('supporters', 'NNS'), 'nmod', ('tax', 'NN')), (('include', 'VBP'), 'obj', ('supporters', 'NNS')), (('remind', 'VB'), 'nsubj', ('me', 'PRP')), (('include', 'VBP'), 'mark', ('that', 'IN')), (('supporters', 'NNS'), 'amod', ('fervent', 'JJ')), (('tax', 'NN'), 'case', ('of', 'IN')), (('tax', 'NN'), 'det', ('this', 'DT')), (('remind', 'VB'), 'obj', ('you', 'PRP')), (('include', 'VBP'), 'nsubj', ('allies', 'NNS')), (('allies', 'NNS'), 'nmod:poss', ('our', 'PRP$')), (('let', 'VB'), 'ccomp', ('remind', 'VB'))}</td>\n",
       "      <td id=\"T_7daf8_row2_col3\" class=\"data row2 col3\" >{(('strong', 'JJ'), 'obl', ('tax', 'NN')), (('like', 'VB'), 'nsubj', ('i', 'PRP')), (('allies', 'NNS'), 'case', ('among', 'IN')), (('like', 'VB'), 'aux', ('would', 'MD')), (('remind', 'VB'), 'ccomp', ('are', 'VBP')), (('remind', 'VB'), 'mark', ('to', 'TO')), (('tax', 'NN'), 'case', ('of', 'IN')), (('like', 'VB'), 'xcomp', ('remind', 'VB')), (('tax', 'NN'), 'det', ('this', 'DT')), (('remind', 'VB'), 'obj', ('you', 'PRP')), (('allies', 'NNS'), 'nmod:poss', ('our', 'PRP$'))}</td>\n",
       "      <td id=\"T_7daf8_row2_col4\" class=\"data row2 col4\" >4.250000</td>\n",
       "      <td id=\"T_7daf8_row2_col5\" class=\"data row2 col5\" >1.052632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "styler = dt.head(3).style.set_table_attributes(\"style='display:inline'\")\n",
    "display_html(styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0542e\" style='display:inline'>\n",
       "  <caption>Highest difference between Jaccard and Gold Standard</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0542e_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_0542e_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_0542e_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_0542e_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_0542e_level0_col4\" class=\"col_heading level0 col4\" >gs</th>\n",
       "      <th id=\"T_0542e_level0_col5\" class=\"col_heading level0 col5\" >jac</th>\n",
       "      <th id=\"T_0542e_level0_col6\" class=\"col_heading level0 col6\" >diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0542e_level0_row0\" class=\"row_heading level0 row0\" >56</th>\n",
       "      <td id=\"T_0542e_row0_col0\" class=\"data row0 col0\" >Van Orden Report (A5-0241/2000)</td>\n",
       "      <td id=\"T_0542e_row0_col1\" class=\"data row0 col1\" >Van Orden report (A5-0241 / 2000)</td>\n",
       "      <td id=\"T_0542e_row0_col2\" class=\"data row0 col2\" >{(('report', 'NNP'), 'compound', ('van', 'NNP')), (('a5', 'NN'), 'nummod', ('0241/2000', 'CD')), (('report', 'NNP'), 'compound', ('orden', 'NNP')), (('report', 'NNP'), 'dep', ('a5', 'NN'))}</td>\n",
       "      <td id=\"T_0542e_row0_col3\" class=\"data row0 col3\" >{(('a5', 'NN'), 'nummod', ('0241', 'CD')), (('report', 'NN'), 'compound', ('orden', 'NNP')), (('2000', 'CD'), 'dep', ('/', 'SYM')), (('a5', 'NN'), 'nmod', ('2000', 'CD')), (('report', 'NN'), 'dep', ('a5', 'NN')), (('orden', 'NNP'), 'compound', ('van', 'NNP'))}</td>\n",
       "      <td id=\"T_0542e_row0_col4\" class=\"data row0 col4\" >5.000000</td>\n",
       "      <td id=\"T_0542e_row0_col5\" class=\"data row0 col5\" >0.000000</td>\n",
       "      <td id=\"T_0542e_row0_col6\" class=\"data row0 col6\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0542e_level0_row1\" class=\"row_heading level0 row1\" >15</th>\n",
       "      <td id=\"T_0542e_row1_col0\" class=\"data row1 col0\" >Tunisia</td>\n",
       "      <td id=\"T_0542e_row1_col1\" class=\"data row1 col1\" >Tunisia</td>\n",
       "      <td id=\"T_0542e_row1_col2\" class=\"data row1 col2\" >set()</td>\n",
       "      <td id=\"T_0542e_row1_col3\" class=\"data row1 col3\" >set()</td>\n",
       "      <td id=\"T_0542e_row1_col4\" class=\"data row1 col4\" >5.000000</td>\n",
       "      <td id=\"T_0542e_row1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
       "      <td id=\"T_0542e_row1_col6\" class=\"data row1 col6\" >5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt['diff'] = abs(dt['jac'] - dt['gs'])\n",
    "dt_worst = dt.sort_values(by=['diff'], ascending=False).head(2)\n",
    "df1_styler = dt_worst.style.set_table_attributes(\"style='display:inline'\").set_caption('Highest difference between Jaccard and Gold Standard')\n",
    "display_html(df1_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3280739664753573"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(dt['gs'], dt['jac'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is it relevant to compute the dependency triples?**\n",
    "\n",
    "Comparing the dependency triples like we are doing now is not relevant for the STS task. CoreNLP takes in a raw text and runs a series of steps (tokenize, split, POS, lemma, ner, deparse) to obtain a final set of annotations. In this case, we are using it to extract the dependency triples, however, as we have seen, we obtain the worst Pearson correlation we have seen so far. Hence, it does not seem that important to calculate these triples in order to correctly solve the STS task. \n",
    "\n",
    "Perhaps using the CoreNLP to extract the POS tags of these sets might be better than using basic NLTK POS tags. However, using the entire set of triples to compute the Jaccard similarity for the STS results in worse results than just comparing the tokens. \n",
    "\n",
    "The dependency triples basically contain too much information about the sentence and how it is built. Hence, any small difference in the sentence will make the Jaccard similarity return bad results. We might consider using this as another Feature, but our expectations for this to be relevant on the STS task is low."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
