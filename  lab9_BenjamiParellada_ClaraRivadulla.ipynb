{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#!pip install spacy==2.1.0\n","!python -m spacy download en_core_web_sm\n","!pip install neuralcoref\n","\n","import spacy\n","import neuralcoref\n","\n","nlp = spacy.load('en_core_web_sm')\n","neuralcoref.add_to_pipe(nlp)"],"metadata":{"id":"8gI664welIj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Lab 9: Coreference\n","\n","For the ninth practical of the subject, \n","\n","The statement is:\n","\n","1. Consider the first paragraph in Alice’s Adventures in Wonderland, by Lewis Carroll:\n","\n","```\n","Alice was beginning to get very tired of sitting by her sister on the bank, \n","and of having nothing to do: once or twice she had peeped into the book her \n","sister was reading, but it had no pictures or conversations in it, ‘and what \n","is the use of a book,’ thought Alice ‘without pictures or conversations?’\n","```\n","\n","2. Apply the spaCy coreference solver to the previous paragraph.\n","3. Show the coreference chains.\n","4. What do you think about them? Justify your answer."],"metadata":{"id":"9bh4BLl2lLAH"}},{"cell_type":"code","source":["first_paragraph = \"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversations?'\"\n","doc = nlp(first_paragraph)"],"metadata":{"id":"6MLF_K7ClSBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Has any coreference has been resolved in the Doc?\n","doc._.has_coref"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hku2VUOoFqD","executionInfo":{"status":"ok","timestamp":1669548980265,"user_tz":-60,"elapsed":628,"user":{"displayName":"Benjami Parellada Calderer","userId":"12702389916161093001"}},"outputId":"7cb864e7-a3e8-4386-9734-1c6c6944aa1b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["# All the clusters of corefering mentions in the Doc\n","for cluster in doc._.coref_clusters:\n","  print('Entity:', cluster[0])\n","  print('Coreferences to entity:', cluster[0:])\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zU7PeH4oLc6","executionInfo":{"status":"ok","timestamp":1669548980266,"user_tz":-60,"elapsed":23,"user":{"displayName":"Benjami Parellada Calderer","userId":"12702389916161093001"}},"outputId":"40e4cd06-0b2f-4303-f384-39128cab3437"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Entity: Alice\n","Coreferences to entity: [Alice, her, she, her, Alice ']\n","\n","Entity: her sister\n","Coreferences to entity: [her sister, her sister]\n","\n","Entity: it\n","Coreferences to entity: [it, it]\n","\n"]}]},{"cell_type":"code","source":["# Increase the greedyness to coreference 'it' better\n","nlp.remove_pipe(\"neuralcoref\")\n","neuralcoref.add_to_pipe(nlp, greedyness = 0.52)\n","doc = nlp(first_paragraph)\n","# All the clusters of corefering mentions in the Doc\n","for cluster in doc._.coref_clusters:\n","  print('Entity:', cluster[0])\n","  print('Coreferences to entity:', cluster[0:])\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voiNsu9gsnV6","executionInfo":{"status":"ok","timestamp":1669548980266,"user_tz":-60,"elapsed":17,"user":{"displayName":"Benjami Parellada Calderer","userId":"12702389916161093001"}},"outputId":"efa0eb31-32de-46d5-ac14-29b3c17c5739"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Entity: Alice\n","Coreferences to entity: [Alice, her, she, her, Alice ']\n","\n","Entity: her sister\n","Coreferences to entity: [her sister, her sister]\n","\n","Entity: the book her sister was reading\n","Coreferences to entity: [the book her sister was reading, it, it]\n","\n"]}]},{"cell_type":"code","source":["# testing with an increased greedyness\n","nlp.remove_pipe(\"neuralcoref\")\n","neuralcoref.add_to_pipe(nlp, greedyness = 0.56)\n","doc = nlp(first_paragraph)\n","# All the clusters of corefering mentions in the Doc\n","for cluster in doc._.coref_clusters:\n","  print('Entity:', cluster[0])\n","  print('Coreferences to entity:', cluster[0:])\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rszec7N329zW","executionInfo":{"status":"ok","timestamp":1669548980266,"user_tz":-60,"elapsed":10,"user":{"displayName":"Benjami Parellada Calderer","userId":"12702389916161093001"}},"outputId":"48c430b1-c7ba-4460-df8d-578dc8e0b41b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Entity: Alice\n","Coreferences to entity: [Alice, her, she, her, Alice, Alice ']\n","\n","Entity: sitting by her sister on the bank\n","Coreferences to entity: [sitting by her sister on the bank, the bank]\n","\n","Entity: her sister\n","Coreferences to entity: [her sister, her sister]\n","\n","Entity: the book her sister was reading\n","Coreferences to entity: [the book her sister was reading, it, it]\n","\n"]}]},{"cell_type":"code","source":["# testing with increased greediness\n","nlp.remove_pipe(\"neuralcoref\")\n","neuralcoref.add_to_pipe(nlp, greedyness = 0.6)\n","doc = nlp(first_paragraph)\n","# All the clusters of corefering mentions in the Doc\n","for cluster in doc._.coref_clusters:\n","  print('Entity:', cluster[0])\n","  print('Coreferences to entity:', cluster[0:])\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLWoPlaD3yQu","executionInfo":{"status":"ok","timestamp":1669548980267,"user_tz":-60,"elapsed":8,"user":{"displayName":"Benjami Parellada Calderer","userId":"12702389916161093001"}},"outputId":"85bf99e3-0f10-4398-b86f-31e834b3e8aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Entity: Alice\n","Coreferences to entity: [Alice, sitting by her sister on the bank, her, her sister, the bank, having nothing to do, nothing to do, she, the book her sister was reading, her, her sister, it, no pictures or conversations, conversations, it, the use of a book, a book, Alice, Alice ', pictures or conversations, conversations]\n","\n"]}]},{"cell_type":"markdown","source":["## Conclusions\n","\n","Corerefence is useful in determining which mentions in a discourse refer to\n","the same real world entity, property or situation. This can be applied in many areas of NLP, for example, it is required to fully understand a text in reading machines, extract information, automatic summarization, and question answering.\n","\n","In the STS task, this might not seem as useful, since usually we only have one sentence and the corefrences are usually resolved from previous context. However, it might be the case that in one sentence the entity appears more than once, and, in the other sentence, it appears once and then it appears as pronouns appears. In this case, resolving the coreferences could potentially help in the Jaccard similarity.\n","\n","**What do you think about them? Justify your answer.**\n","\n","Observing the obtained clusters, we see that the main entities and their coreferences have been found. However, in the original - default greediness at 0.5 - case, the entity `book` failed to be coreferenced properly. Instead of taking the entity `book` it took `it` which is not something we would want since `it` is a pronoun and by itself does not really mean much.\n","\n","Increasing the greediness, where more greedy means more coreference links, we see that it removes `it` and returns an entity that is not a pronoun for the cluster. Nevertheless, it took perhaps way too much of the entity as it took `the book her sister was reading`. Trying fine-tune the greediness to only get `book` seems fruitless, as reducing the parameter we return to the default case, where it took `it` as the entity.\n","\n","Moreover, we see that increasing the greediness even more, the coreferences start to degrade. For example, with `0.56`, we get a coreference from `the bank` to `sitting by her sister on the bank`, which does not really seem helpful at all, since they are part of the same sentence. Increasing the greediness even more to `0.6`, starts to agglomerate everything in the `Alice` cluster.\n"],"metadata":{"id":"YoEVHL8yqCx4"}}]}